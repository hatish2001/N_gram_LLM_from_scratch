{"cells":[{"cell_type":"code","execution_count":81,"id":"1729a794","metadata":{},"outputs":[],"source":["import torch  # PyTorch for building and training the neural network\n","import torch.nn.functional as F  # Provides functions for different neural network operations\n","import matplotlib.pyplot as plt  # For plotting and visualizing data\n","%matplotlib inline  # Ensures that plots appear inline within the Jupyter notebook"]},{"cell_type":"code","execution_count":82,"id":"db92deec","metadata":{},"outputs":[],"source":["# Reading in the names dataset\n","# The file 'names.txt' is assumed to contain a list of names, one per line\n","words = open('names.txt', 'r').read().splitlines()"]},{"cell_type":"code","execution_count":83,"id":"62e8b34c","metadata":{},"outputs":[],"source":["# Building the vocabulary of characters from the dataset\n","# 'chars' contains all unique characters in the dataset sorted alphabetically\n","# 'stoi' is a dictionary that maps each character to a unique integer (starting from 1)\n","# '.' is used as a special end-of-sequence character, mapped to 0\n","chars = sorted(list(set(''.join(words))))\n","stoi={s : i+1 for i,s in enumerate(chars)}\n","stoi['.'] = 0  # Map the end character '.' to 0\n","itos = {i:s for s,i in stoi.items()}  # Reverse mapping from integers to characters"]},{"cell_type":"code","execution_count":84,"id":"2ec7a600","metadata":{},"outputs":[],"source":["# Constructing the dataset\n","# 'block_size' determines how many characters are used as input to predict the next character\n","# X will contain the context (input) and Y will contain the next character (output)\n","block_size = 3\n","X,Y= [],[]\n","for w in words:\n","    context = [0] * block_size  # Start with a padding context of size block_size\n","    for ch in w + '.':  # Loop through each character in the word, ending with '.'\n","        ix = stoi[ch]  # Convert character to integer using the vocabulary\n","        X.append(context)  # Store the context as an input example\n","        Y.append(ix)  # Store the corresponding target output\n","        context = context[1:] + [ix]  # Shift the context window by one character\n","\n","# Convert the lists to tensors for training\n","X = torch.tensor(X)\n","Y= torch.tensor(Y)"]},{"cell_type":"code","execution_count":166,"id":"98760af7","metadata":{},"outputs":[],"source":["# Initialize a random embedding matrix C of size (27, 10), where 27 represents the number of unique characters (including '.')\n","C = torch.randn(27,10)"]},{"cell_type":"code","execution_count":167,"id":"0953ddc0","metadata":{},"outputs":[],"source":["w1 = torch.randn(30,200)\n","b1 = torch.randn(200)"]},{"cell_type":"code","execution_count":168,"id":"39455a43","metadata":{},"outputs":[],"source":["w2 = torch.randn(200,27)\n","b2 = torch.randn(27)"]},{"cell_type":"code","execution_count":169,"id":"ed50c41e","metadata":{},"outputs":[],"source":["parameters = [C, w1, b1, w2, b2]"]},{"cell_type":"code","execution_count":170,"id":"c2b9cbbd","metadata":{},"outputs":[],"source":["for p in parameters:\n","    p.requires_grad = True"]},{"cell_type":"code","execution_count":173,"id":"4efe5c71","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(2.0215, grad_fn=<NllLossBackward0>)\n"]}],"source":["#Training of the network\n","lossi=[]\n","step=[]\n","for i in range(200):\n","    ix = torch.randint(0, X.shape[0], (32,))\n","    emb = C[X[ix]]\n","    h1 = torch.tanh(emb.view(-1,30) @ w1 + b1)\n","    logits = h1 @ w2 + b2\n","    loss = F.cross_entropy(logits,Y[ix])\n","    \n","    #Back_Propagation:\n","    for p in parameters:\n","        p.grad = None\n","    loss.backward()\n","    \n","    #update:\n","    for p in parameters:\n","        if p.grad is not None:\n","            p.data+= -0.01 * p.grad\n","    step.append(i)\n","    lossi.append(loss.log10().item())\n","print(loss)"]},{"cell_type":"code","execution_count":177,"id":"5096ff6e","metadata":{},"outputs":[],"source":["emb1= C[X]"]},{"cell_type":"code","execution_count":221,"id":"2bdbea09","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["zam.\n","azzeni.\n","kolaw.\n","sarrie.\n","nav.\n","kagtermanel.\n","deonzy.\n","conianrick.\n","kaizana.\n","elett.\n","yazinett.\n","ghy.\n","ausefa.\n","jayvon.\n","nick.\n","itsabetza.\n","jackhammilethayevayana.\n","jarvin.\n","natangeloannahreen.\n","ansrid.\n"]}],"source":["#Generate function\n","def generate(number_of_names):\n","    for i in range(number_of_names):\n","        context = [0]* block_size\n","        out = []\n","        while True: \n","            emb = C[torch.tensor([context])]\n","            h1 = torch.tanh(emb.view(1,-1) @ w1 + b1)\n","            h2 = h1 @ w2 + b2 \n","            logits = F.softmax(h2, dim=1)\n","            ix= torch.multinomial(logits, num_samples=1).item()\n","            context = context[1:]+ [ix]\n","            out.append(itos[ix])\n","            if ix==0: \n","                break\n","        print(''.join(out))\n","\n","generate(20)"]},{"cell_type":"code","execution_count":null,"id":"f01fb6a2","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"46d42793","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":5}
